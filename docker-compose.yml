services:

# install docker first: 
# curl -fsSL https://get.docker.com | sh
# verify installation:
# docker --version

# ----------- real time data ----------------#
  kafka:
    image: confluentinc/cp-kafka:7.6.0
    container_name: kafka
    ports:
      - "9092:9092"
      - "9093:9093"
    environment:
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      KAFKA_LISTENERS: "INTERNAL://0.0.0.0:19092,EXTERNAL://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093"
      KAFKA_ADVERTISED_LISTENERS: "INTERNAL://kafka:19092,EXTERNAL://159.65.41.22:9092"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: "INTERNAL"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      CLUSTER_ID: "CQdFOKLdQ8Si0WWDeEUgGg"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_BROKER_ID: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_HEAP_OPTS: "-Xmx256M -Xms128M"

      KAFKA_LOG_RETENTION_MINUTES: 15           # keep messages for 15 min
      KAFKA_LOG_SEGMENT_BYTES: 77428800       # 50 MB per segment
      KAFKA_LOG_RETENTION_BYTES: 268435456  # 256 MB total
      KAFKA_DELETE_TOPIC_ENABLE: "true"       # allow deleting topics

    volumes:
      - kafka-data:/var/lib/kafka/data       # <-- persist Kafka
    restart: unless-stopped

    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10

    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

# ----------- visualization ----------------#

  # http://159.65.41.22:3000

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
      GF_INSTALL_PLUGINS: grafana-clickhouse-datasource

      # === EMBEDDING + ANONYMOUS ACCESS ===
      GF_SECURITY_ALLOW_EMBEDDING: "true"
      GF_AUTH_ANONYMOUS_ENABLED: "true"
      GF_AUTH_ANONYMOUS_ORG_ROLE: "Viewer"
      GF_AUTH_DISABLE_LOGIN_FORM: "false"

      # === URL SETTINGS ===
      # this is for if we do not want to view it on a local, unsecured connection.

      GF_SERVER_DOMAIN: grafana.erickopen.com
      GF_SERVER_ROOT_URL: https://grafana.erickopen.com/
      GF_SERVER_SERVE_FROM_SUB_PATH: "false"

      # requires nginx to be installed on the server to view via grafana.erickopen.com

    volumes:
      - grafana-data:/var/lib/grafana
      - ./provisioning/dashboards:/etc/grafana/provisioning/dashboards
      - ./dashboards:/var/lib/grafana/dashboards
    restart: unless-stopped

    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

# ----------- monitoring ----------------#

# checks if services are up
  blackbox:
    image: prom/blackbox-exporter:latest
    container_name: blackbox
    ports:
      - "9115:9115"
    command:
      - "--config.file=/etc/blackbox/blackbox.yml"
    volumes:
      - ./blackbox.yml:/etc/blackbox/blackbox.yml
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # collects information for each continer
  # will host at http://159.65.41.22:8080/metrics
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    ports:
      - "8080:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # tracks host level metrics
  # http://159.65.41.22:9100/metrics
  node_exporter:
    image: prom/node-exporter:latest
    container_name: node_exporter
    ports:
      - "9100:9100"
    restart: unless-stopped    
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # scrapes endpoints for metrics/alerts. the central "brain"
  # http://159.65.41.22:9090/targets
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--storage.tsdb.retention.time=12h"
      - "--storage.tsdb.min-block-duration=2h"
      - "--storage.tsdb.max-block-duration=2h"
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

# ----------- main_app ----------------#
  main_app:
    build: .
    container_name: main_app
    env_file:
      - .env
    ports:
      - "8001:8001"
    depends_on:
      kafka:
        condition: service_healthy
    volumes:
      - ./log_data:/app/log_data
    restart: unless-stopped
    stop_grace_period: 20s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

# ----------- log rotation --------- #

volumes:
  grafana-data:
  kafka-data:
  prometheus-data: